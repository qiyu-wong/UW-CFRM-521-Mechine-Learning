{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<h1>\n",
    "<center>CFRM 521, Spring 2020</center>\n",
    "</h1>\n",
    "\n",
    "<h1>\n",
    "<center>[Please insert your name(s) here]</center>\n",
    "</h1>\n",
    "\n",
    "<h1>\n",
    "<center>Homework 1</center>\n",
    "</h1>\n",
    "\n",
    "* **Due: Monday 20th April 2020, at 11:59pm**\n",
    "\n",
    "\n",
    "* You may submitted this homework with one other classmate. If you are submitting in a group of two, only one of you must submit the homework. The other must make a comment on Canvas (where you would submit the homework) mentioning that they are submitting with another person. Also, please include both of your names in the homework submission.\n",
    "\n",
    "\n",
    "* Late homework are allowed, **but a 10% penalty per day applies.** Example: submitting on Tuesday 00:01am results in 10% penalty, on Wednesday 00:01am results in 20% penalty, etc. Your last submission is considered for calculating the penalty.\n",
    "\n",
    "\n",
    "*  Please use this Jupyter notebook as a template for your solutions. Your solution must be submitted as one Jupyter notebook. You are allowed to use code from the textbook, textbook website, or lecture notes. However, please go over the code you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing Housing data\n",
    "\n",
    "Consider the California housing data from Chapter 2 of the textbook. Let us fetch the data (see Lecture 1 notes for explanation of the following code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "\n",
    "def fetch_housing_data(housing_url, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "HOUSING_URL = (\"https://raw.githubusercontent.com/ageron/\"+\n",
    "               \"handson-ml2/master/datasets/housing/housing.tgz\")\n",
    "fetch_housing_data(HOUSING_URL)\n",
    "data = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create stratified test and training sets based on different income categories (see lecture one notes for explanation of the code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"income_cat\"] = np.ceil(data[\"median_income\"] / 1.5)\n",
    "data[\"income_cat\"].where(data[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"income_cat\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]\n",
    "    \n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us separate features (`X_raw`) and the response variable (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "y = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Handling missing values\n",
    "\n",
    "Let us find out if there is any missing value in our features. As the code below indicates, out of 16512 observations, 158 have missing values. Further inspection shows that `total_bedrooms` has missing values (only a few missing values is shown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 9)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 9)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw[X_raw.isnull().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>-118.30</td>\n",
       "      <td>34.07</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3759.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3296.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>2.2708</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>-117.86</td>\n",
       "      <td>34.01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4632.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>5.1762</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17923</th>\n",
       "      <td>-121.97</td>\n",
       "      <td>37.35</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>4.6328</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13656</th>\n",
       "      <td>-117.30</td>\n",
       "      <td>34.05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1.6675</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19252</th>\n",
       "      <td>-122.79</td>\n",
       "      <td>38.48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6837.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3468.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>3.1662</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "4629     -118.30     34.07                18.0       3759.0             NaN   \n",
       "6068     -117.86     34.01                16.0       4632.0             NaN   \n",
       "17923    -121.97     37.35                30.0       1955.0             NaN   \n",
       "13656    -117.30     34.05                 6.0       2155.0             NaN   \n",
       "19252    -122.79     38.48                 7.0       6837.0             NaN   \n",
       "\n",
       "       population  households  median_income ocean_proximity  \n",
       "4629       3296.0      1462.0         2.2708       <1H OCEAN  \n",
       "6068       3038.0       727.0         5.1762       <1H OCEAN  \n",
       "17923       999.0       386.0         4.6328       <1H OCEAN  \n",
       "13656      1039.0       391.0         1.6675          INLAND  \n",
       "19252      3468.0      1405.0         3.1662       <1H OCEAN  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw[X_raw.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Use the `sklearn.impute.SimpleImputer` class to fill the missing values in the numerical features (everything except `ocean_proximity`) with the median of the corresponding feature.\n",
    "\n",
    "Hint: In Chapter 2 of the textbook, under section \"Prepare the Data for Machine Learning Algorithms\", you can find explanation how to fill missing values. Also, take a look at the corresponding Jupyter notebook from the textbook website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_raw_num = X_raw.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(X_raw_num)\n",
    "S = imputer.transform(X_raw_num)\n",
    "X_tr = pd.DataFrame(S, columns=X_raw_num.columns,index=X_raw_num.index)\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Handling categorical features\n",
    "ML algorithms generally work with numerical values. So, we need to convert categorical (or text) features to numerical values. One way is to simply map each category to an integer. Another alternative is to use **one-hot encoding**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Read subsection \"Handling Text and Categorical Attributes\" in Chapter 2 of the textbook to learn one-hot encoding and its advantages. Then use the `sklearn.preprocessing.OrdinalEncoder` class and the `sklearn.preprocessing.OneHotEncoder` class to transform the `ocean_proximity` feature to integers and one-hot vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "X_cat = X_raw[[\"ocean_proximity\"]]\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_cat_encoded = ordinal_encoder.fit_transform(X_cat)\n",
    "X_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "X_cat_1hot = cat_encoder.fit_transform(X_cat)\n",
    "X_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Feature scaling\n",
    "\n",
    "Many ML algorithms do not perform well if the features have different scales (some very small, and others very large). In such scenarios, one should transform the features so that they have similar range of values. There are two common ways to achieve this. In **min-max** scaling, we subtract the feature from its minimum value and then divide by its range (i.e. maximum value minus minimum value) so that the scaled values are between 0 and 1. In **standardization**, we subtract the values from the average and divide by the standard deviation, so that the transformed values has mean 0 and variance 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Use the `sklearn.preprocessing.MinMaxScaler` class and `sklearn.preprocessing.StandardScaler` class to scale the numerical features using min-max scaling and standardization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24501992, 0.50478215, 0.7254902 , ..., 0.01981558, 0.06292009,\n",
       "        0.15201859],\n",
       "       [0.24103586, 0.47927736, 0.25490196, ..., 0.00849239, 0.02072442,\n",
       "        0.40837368],\n",
       "       [0.71215139, 0.02444208, 0.58823529, ..., 0.02614984, 0.08588499,\n",
       "        0.1629081 ],\n",
       "       ...,\n",
       "       [0.79183267, 0.16471838, 0.15686275, ..., 0.05871801, 0.14245706,\n",
       "        0.19119736],\n",
       "       [0.6314741 , 0.1360255 , 0.58823529, ..., 0.03792147, 0.0660941 ,\n",
       "        0.24569316],\n",
       "       [0.18924303, 0.55579171, 1.        , ..., 0.03548306, 0.11893204,\n",
       "        0.21207294]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_scaler=MinMaxScaler()\n",
    "X_minmax=minmax_scaler.fit_transform(X_tr)\n",
    "X_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15604281,  0.77194962,  0.74333089, ..., -0.63621141,\n",
       "        -0.42069842, -0.61493744],\n",
       "       [-1.17602483,  0.6596948 , -1.1653172 , ..., -0.99833135,\n",
       "        -1.02222705,  1.33645936],\n",
       "       [ 1.18684903, -1.34218285,  0.18664186, ..., -0.43363936,\n",
       "        -0.0933178 , -0.5320456 ],\n",
       "       ...,\n",
       "       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.60790363,\n",
       "         0.71315642, -0.3167053 ],\n",
       "       [ 0.78221312, -0.85106801,  0.18664186, ..., -0.05717804,\n",
       "        -0.37545069,  0.09812139],\n",
       "       [-1.43579109,  0.99645926,  1.85670895, ..., -0.13515931,\n",
       "         0.3777909 , -0.15779865]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler=StandardScaler()\n",
    "X_std=standard_scaler.fit_transform(X_tr)\n",
    "X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Transformation pipelines\n",
    "\n",
    "Usually, we have to perform several steps before the data is ready to be fed to an ML algorithm. Scikit-Learn's `Pipeline` class provides a systematic way of \"packaging\" such sequence of transformations.\n",
    "\n",
    "**Task:** Read the subsection titled \"transformation pipelines\" in Chapter 2 of the textbook. Then, create one pipeline that applies the transformations on part (a), (b) (use one-hot encoding), and (c) (use standardization) to the \"raw\" features `X_raw`. Call your transformed data `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "('imputer', SimpleImputer(strategy=\"median\")),\n",
    "('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "num_attribs = list(X_raw_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "(\"num\", num_pipeline, num_attribs),\n",
    "(\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "\n",
    "X = full_pipeline.fit_transform(X_raw)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fine-tuning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Linear regression\n",
    "\n",
    "**Task:** Use the `sklearn.linear_model.LinearRegression` class to fit a multiple linear regression to the training set in Question 1. Use the processed features `X` that you obtained in 1.(d) as predictors and `y` (the median house values) as the response. Return fitted values of the response for the first 10 observations of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0, 127900.0, 500001.0, 140200.0, 95000.0, 500001.0]\n",
      "Predict: [211574.39523832555, 321345.1051371902, 210947.51983800187, 61921.01197837471, 192362.3296111861, 154821.86099030558, 426129.59146333823, 229666.36167750446, 141483.54356475634, 12084.195020017622]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "some_data = X[:10]\n",
    "some_labels = y.iloc[:10]\n",
    "print(\"Labels:\", list(some_labels))\n",
    "print(\"Predict:\", list(lin_reg.predict(some_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) RMSE and MAE\n",
    "\n",
    "As we have seen in CFRM 502, we can measure the out-of-sample performance with root mean square error (RMSE) and mean absolute error (MAE). \n",
    "\n",
    "**Task:** Use `mean_squared_error` and `mean_absolute_error` functions from `sklearn.metrics` to calculate the in-sample RMSE and MAE of the linear regressor that you fit in part (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69050.98178244587\n",
      "49906.94142223288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_predictions = lin_reg.predict(X)\n",
    "lin_mse = mean_squared_error(y, y_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "lin_mae = mean_absolute_error(y, y_predictions)\n",
    "print(lin_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Cross validation\n",
    "\n",
    "In part (b), we evaluated the in-sample performance of the linear regression model. To obtain out-of-sample performance, we may use K-fold cross validation as was explained in Lecture 2.\n",
    "\n",
    "**Task:** Use the `cross_val_score` function from `sklearn.model_selection` to perform 20-fold  cross validation on the linear regressor from part (a) and return the values of **MAE** (use the argument `scoring=\"neg_mean_absolute_error\"`). Return the 20 MAE scores as well as their mean and standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [52128.74309417 45734.66433295 50755.22456793 47840.45345004\n",
      " 49264.3935965  49998.72004939 49848.56169884 53690.92931375\n",
      " 52060.21094438 48484.83022226 52802.79659221 50376.81642374\n",
      " 47184.38509378 49163.95427331 47702.70481427 50525.42113931\n",
      " 51272.31717921 51684.20719774 50591.06918414 48426.96686148]\n",
      "Mean: 49976.86850146998\n",
      "Standard deviation: 1976.5152666639403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lin_reg, X, y,scoring=\"neg_mean_absolute_error\", cv=20)\n",
    "lin_mae_scores = (-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "display_scores(lin_mae_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Alternatives to linear regression\n",
    "Let us consider fitting two alternative models, namely, **decision trees** and **random forests**. These models will be discussed during future lectures. The following code fits a decision tree and obtain the fitted response for the first 10 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=42, splitter='best')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_reg = DecisionTreeRegressor(random_state=42)\n",
    "dt_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([286600., 340600., 196900.,  46300., 254500., 127900., 500001.,\n",
       "       140200.,  95000., 500001.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_reg.predict(X[:10,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code do the same things for the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=2, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor(bootstrap=True, n_estimators=10,\n",
    "                                max_features=2, random_state=42)\n",
    "rf_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([252210. , 350830.1, 202920. ,  52360. , 241080. , 114640. ,\n",
       "       466600.6, 202360. ,  94890. , 384110.7])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_reg.predict(X[:10,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Find the in-sample performance of the decision tree and the random forest using MAE on the training set. Also, find the out-of-sample performance by the 20-fold cross validation as you did in part (c). Interpret the results. Which model has the best in-sample performance? Which model has the best out-of-sample performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_mae: 0.0\n",
      "Scores: [45750.65133172 38632.7094431  43592.06053269 44728.73486683\n",
      " 42278.7251816  46432.2433414  42164.68038741 47100.65012107\n",
      " 44650.40556901 42894.47215496 47275.23244552 47095.44430993\n",
      " 47099.79757576 44367.56242424 43305.13454545 43804.40242424\n",
      " 43356.04727273 48016.77939394 44114.70545455 42722.96      ]\n",
      "Mean: 44469.169938806954\n",
      "Standard deviation: 2240.992398053244\n",
      "rf_mae: 14797.653906250001\n",
      "Scores: [39384.00072639 33155.38280872 35883.43075061 37209.92397094\n",
      " 36649.50992736 38476.97711864 35869.85423729 38949.37336562\n",
      " 37980.79358354 35885.24939467 39133.39249395 38779.46549637\n",
      " 36704.21418182 38004.79672727 34175.1169697  39735.49551515\n",
      " 38031.02848485 38771.17539394 38312.22581818 35254.19151515]\n",
      "Mean: 37317.27992400763\n",
      "Standard deviation: 1768.8407619514485\n"
     ]
    }
   ],
   "source": [
    "dt_mae = mean_absolute_error(y, dt_reg.predict(X))\n",
    "print(\"dt_mae:\",dt_mae)\n",
    "\n",
    "dt_scores = cross_val_score(dt_reg, X, y,scoring=\"neg_mean_absolute_error\", cv=20)\n",
    "dt_mae_scores = (-dt_scores)\n",
    "display_scores(dt_mae_scores)\n",
    "\n",
    "rf_mae = mean_absolute_error(y, rf_reg.predict(X))\n",
    "print(\"rf_mae:\",rf_mae)\n",
    "\n",
    "rf_scores = cross_val_score(rf_reg, X, y,scoring=\"neg_mean_absolute_error\", cv=20)\n",
    "rf_mae_scores = (-rf_scores)\n",
    "display_scores(rf_mae_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Choosing good values of hyperparameters using Cross Validation\n",
    "\n",
    "Most ML algorithms have **hyperparameters**. These hyperparameters control the learning process and should not be confused with the model parameters (which are the unknown values that are being estimated). For example, the random forest algorithm has 3 hyperparameters, namely `bootstrap`, `n_estimators`, and `max_features`. To fine-tune a model, we should find good values of hyperparameters based on out-of-sample performance.\n",
    "\n",
    "**Task:** Read sections titled \"Grid Search\" and \"Randomized Search\" in Chapter 2 of the textbook. Then, use the `sklearn.model_selection.GridSearchCV` class and `sklearn.model_selection.RandomizedSearchCV` class to choose a good set of values of the `bootstrap`, `n_estimators`, and `max_features` hyperparamters of the random forest algorithm.  Use 5-fold cross-validation when searching for the hyper parameters. But, report MAE values for the 20-fold cross validation of the best model you find. Also, report the best values of the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=8, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=30, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [35645.4693301  28416.21299435 30322.82215496 31230.87655367\n",
      " 31334.00221953 32894.58684423 30600.93910412 34415.14717514\n",
      " 33855.72675545 31017.7559322  33906.72683616 34813.29834544\n",
      " 32355.98525253 32726.6680404  30850.23866667 33241.50949495\n",
      " 32944.17046465 34553.4640404  33067.24040404 31013.82521212]\n",
      "Mean: 32460.333291055846\n",
      "Standard deviation: 1779.5152662616097\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(bootstrap=True, n_estimators=30,\n",
    "                                max_features=8, random_state=42)\n",
    "rf_reg.fit(X, y)\n",
    "rf_scores = cross_val_score(rf_reg, X, y,scoring=\"neg_mean_absolute_error\", cv=20)\n",
    "rf_mae_scores =(-rf_scores)\n",
    "display_scores(rf_mae_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "\n",
    "parameters = {'n_estimators' : sp_randInt(1, 50), 'max_features': sp_randInt(1, 10)}\n",
    "randm = RandomizedSearchCV(forest_reg, parameters,n_iter = 100, scoring=\"neg_mean_absolute_error\",cv = 5)\n",
    "randm.fit(X, y)\n",
    "randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(bootstrap=True, n_estimators=41,\n",
    "                                max_features=8, random_state=42)\n",
    "rf_reg.fit(X, y)\n",
    "\n",
    "rf_scores = cross_val_score(rf_reg, X, y,scoring=\"neg_mean_absolute_error\", cv=20)\n",
    "rf_mae_scores =(-rf_scores)\n",
    "display_scores(rf_mae_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f) Evaluating your final model using the test set\n",
    "\n",
    "The last step of a ML project is to evaluate your (fine-tuned) model using the test set. The goal of this step is to estimate the out-of-sample performance of your trained model on new data. **Be careful not to train your model using the test set!** Do not use `.fit()` or `.fit_tranform()` of your estimators or pipelines. Also, **do not fine tune your hyperparameters after finding out the performance of a model on the test set!** Doing so is data snooping.\n",
    "\n",
    "**Task:** Report the MAE and RMSE of your best model in part (e). Compare with the average scores of the 20-fold cross validation using the training set. Are the test scores better than the average of the cross validation scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "test_p = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "testing = full_pipeline.transform(test_raw)\n",
    "\n",
    "test_predictions = rf_reg.predict(testing)\n",
    "\n",
    "test_mse = mean_squared_error(test_p, test_predictions)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "print(test_rmse)\n",
    "\n",
    "test_mae = mean_absolute_error(test_p, test_predictions)\n",
    "print(test_mae)\n",
    "\n",
    "#The test score is not better than the average of the cross validation scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Regularizing linear regression\n",
    "\n",
    "Consider the housing data set from Questions 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) learning curves\n",
    "\n",
    "Obtain learning curves for the linear regression model that you fitted in Question 2.(a). To make your code faster, do not add one observation at at time to obtain the learning curves. Instead, add, say, 100 observations to obtain subsequent points of the curves. This way, you will end up fitting fewer models (and spend less time). Do the curves indicate over-fitting or under-fitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "def plot_learning_curves(lin_reg, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(100, len(X_train)):\n",
    "        lin_reg.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = lin_reg.predict(X_train[:m])\n",
    "        y_val_predict = lin_reg.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "plot_learning_curves(reg, X, y)\n",
    "\n",
    "#It indicates a underfitting curve. Performance on training data is worse than on testing set. And they are both pretty high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Regularizing\n",
    "\n",
    "If you think your model is over-fitting, try to regularize it with ridge, lasso, or elastic net (one model is sufficient). If the model is under-fitting, add enough polynomial features so that it over-fits the training set, and then regularize it. Find a good value of the regularization hyperparameter(s) by grid search as you did in Question 2.(e) of Homework 1. Report the learning curves of the best model you find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=1, solver=\"cholesky\")\n",
    "ridge_reg.fit(X, y)\n",
    "\n",
    "plot_learning_curves(ridge_reg, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Titanic dataset\n",
    "\n",
    "In this question you will deal with the Titanic dataset, which is a nice \"Tutorial\" example for ML. Take a look at the following page on Kaggle for further information [https://www.kaggle.com/c/titanic/](https://www.kaggle.com/c/titanic/) (you need to register). You can also use the solution of Exercise 3 of Chapter 3 of the textbook which is included in the online Jupyter notebook from [https://github.com/ageron/handson-ml2](https://github.com/ageron/handson-ml2). As always, please experiment with the code instead of just copy-pasting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Load the data and split it into training and test set. Note that you cannot use the `test.csv` from Kaggle, since it does not have the labels (the column `Survived`). You have to create your own traning and test sets using the `train.csv` (use 20% of the data for testing). Provide a brief description of the features, the label, and summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data= pd.read_csv(\"train.csv\")\n",
    "data\n",
    "#For some reasons, I keep getting error when loading data. And it also happens when running the github textbook solution. So I used downloaded version.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "data.drop(\"Name\", axis=1, inplace=True)\n",
    "data.drop(\"Cabin\", axis=1, inplace=True)\n",
    "data.drop(\"Ticket\", axis=1, inplace=True)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "scale = 2.75\n",
    "data.hist(bins=50, figsize=(5*scale,2*scale), layout=(2,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "Design a pipeline for preprocessing the features. Explain your steps and why you are taking them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data.drop(\"Survived\", axis=1)\n",
    "y = data[\"Survived\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "X_num = X_raw.drop([\"Sex\",\"Embarked\",\"Pclass\"], axis=1)\n",
    "X_cat = X_raw[[\"Sex\",\"Embarked\",\"Pclass\"]]\n",
    "\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "('imputer', SimpleImputer(strategy=\"median\")),\n",
    "('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "('imputer', MostFrequentImputer()),\n",
    "('1hotencode', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "\n",
    "num_attribs = list(X_num)\n",
    "cat_attribs = list(X_cat)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "(\"num\", num_pipeline, num_attribs),\n",
    "(\"cat\", cat_pipeline, cat_attribs),\n",
    "])\n",
    "\n",
    "\n",
    "X = full_pipeline.fit_transform(X_raw)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Train a logistic regression classifier and a `SGDClassifier` (a linear support vector machine trained with SGD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)\n",
    "For the classifiers in part (c), plot precision against recall for various decision thresholds. What do you think is more important in this classification task, decision or recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_scores = cross_val_predict(log_reg, X, y, cv=3,\n",
    "method=\"decision_function\")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y, y_scores)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_scores = cross_val_predict(sgd_clf, X, y, cv=3,\n",
    "method=\"decision_function\")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y, y_scores)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()\n",
    "\n",
    "#recall is more important here for us to classify if passengers survided or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)\n",
    "Plot ROC curve of the classifiers in part (c) and compute their ROC-AUC. Perform, also, 10-fold cross validation and report accuracy. Based on your findings, which classifier is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_scores = cross_val_predict(log_reg, X, y, cv=3,\n",
    "method=\"decision_function\")\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_scores)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_scores = cross_val_predict(sgd_clf, X, y, cv=3,\n",
    "method=\"decision_function\")\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_scores)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y, y_scores)\n",
    "\n",
    "#logistic model is better, its ROC is closer to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)\n",
    "\n",
    "Build a classifier that has over 80% average accuracy using 10-fold cross validation over the training set. Train the classifier over the whole training set and report its accuracy, precision, recall, ROC curve and ROC-AUC over the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
